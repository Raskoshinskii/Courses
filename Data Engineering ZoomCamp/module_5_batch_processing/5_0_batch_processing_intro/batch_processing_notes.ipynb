{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is Batch Processing?\n",
    "Usually the data can be processed in two ways: batch and streaming. \n",
    "\n",
    "**Batch Processing**\n",
    "The data is split into some parts/batches and processed later. For example, yearly data can be split/partitioned on daily bases. In this case, certain day - batch. The most common partitioning levels for the batch processing:\n",
    "- weekly, daily, hourly\n",
    "\n",
    "\n",
    "Streaming data is usually processed in real time (on the fly). Streaming can be considered as a sequence of small batches and similar batch techniques can be applied for data processing. \n",
    "\n",
    "**Batch Processing Advanatages**\n",
    "- Easy to manage (scripts parameterizations)\n",
    "- Horizontal scaling\n",
    "\n",
    "The main disadvantage -> time delay. Jobs are processed after some time, not in real time. In practice, 80% of all jobs are batch and only 20% of them are streaming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Cluster\n",
    "Spark cluster is a **set of executors/workers** that pull the data from the data source (e.g. Data Lake). Number of workers depends on the tasks and can be easily customized. For faster data processing **it's recommended to partition the data** so that all workers are busy during data processing. If number of partitions is small, some workers might not take part in data processing at all and data processing will be inefficient. \n",
    "\n",
    "If the DataFrame or the data is not partitioned, use `spark.repartition()`. Repartitioning is expensive operation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
